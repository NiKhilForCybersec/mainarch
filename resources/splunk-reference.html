<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Splunk Reference | Security Transformation</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:wght@400;500;600;700&family=IBM+Plex+Mono:wght@400;500&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../css/styles.css">
</head>
<body>
  <div class="layout">
        <aside class="sidebar">
      <div class="sidebar-header">
        <div class="sidebar-logo">
          <div class="sidebar-logo-icon">RF</div>
          <div class="sidebar-logo-text">
            <span class="sidebar-logo-title">Security Transformation</span>
            <span class="sidebar-logo-subtitle">RevFlow Analytics</span>
          </div>
        </div>
      </div>
      <nav class="sidebar-nav">
        <div class="nav-section">
          <div class="nav-section-title">Overview</div>
          <a href="../index.html" class="nav-item">Executive Summary</a>
          <a href="../company-profile.html" class="nav-item">Company Profile</a>
          <a href="../security-framework.html" class="nav-item">Security Framework</a>
          <a href="../program-structure.html" class="nav-item">Program Structure</a>
          <a href="../controls-mapping.html" class="nav-item">Controls Mapping</a>
        </div>
        <div class="nav-divider"></div>
        <div class="nav-section">
          <div class="nav-section-title">SIEM Migration</div>
          <a href="../siem/index.html" class="nav-item">SIEM Overview</a>
          <a href="../siem/discovery.html" class="nav-item">Discovery & Assessment</a>
          <a href="../siem/log-sources.html" class="nav-item">Log Source Strategy</a>
          <a href="../siem/log-engineering.html" class="nav-item">Log Engineering</a>
          <a href="../siem/parsing-deep-dive.html" class="nav-item">Parsing Deep Dive</a>
          <a href="../siem/threat-intelligence.html" class="nav-item">Threat Intelligence</a>
          <a href="../siem/detection-engineering.html" class="nav-item">Detection Engineering</a>
          <a href="../siem/detection-anatomy.html" class="nav-item">Detection Anatomy</a>
          <a href="../siem/detection-catalog.html" class="nav-item">Detection Catalog</a>
          <a href="../siem/soar-automation.html" class="nav-item">SOAR &amp; Automation</a>
          <a href="../siem/workbooks.html" class="nav-item">Workbooks &amp; Dashboards</a>
          <a href="../siem/cost-optimization.html" class="nav-item">Cost Optimization</a>
          <a href="../siem/casb-saas-security.html" class="nav-item">CASB &amp; SaaS Security</a>
          <a href="../siem/soc-transition.html" class="nav-item">SOC Transition</a>
        </div>
        <div class="nav-divider"></div>
        <div class="nav-section">
          <div class="nav-section-title">EDR Migration</div>
          <a href="../edr/index.html" class="nav-item">EDR Overview</a>
          <a href="../edr/xdr-detection-model.html" class="nav-item">XDR Detection Model</a>
          <a href="../edr/advanced-hunting.html" class="nav-item">Advanced Hunting</a>
          <a href="../edr/live-response.html" class="nav-item">Live Response</a>
          <a href="../edr/tvm.html" class="nav-item">Vulnerability Management</a>
          <a href="../edr/deployment.html" class="nav-item">MDE Deployment</a>
          <a href="../edr/asr-rules.html" class="nav-item">ASR Rules</a>
          <a href="../edr/device-control.html" class="nav-item">Device Control</a>
          <a href="../edr/compensating-controls.html" class="nav-item">Compensating Controls</a>
          <a href="../edr/coexistence.html" class="nav-item">Coexistence Strategy</a>
          <a href="../edr/eset-removal.html" class="nav-item">ESET Removal</a>
        </div>
        <div class="nav-divider"></div>
        <div class="nav-section">
          <div class="nav-section-title">DLP Migration</div>
          <a href="../dlp/index.html" class="nav-item">DLP Overview</a>
          <a href="../dlp/dlp-catalog.html" class="nav-item">DLP Catalog</a>
          <a href="../dlp/policy-translation.html" class="nav-item">Policy Translation</a>
          <a href="../dlp/rollout-phases.html" class="nav-item">Rollout Phases</a>
          <a href="../dlp/user-communication.html" class="nav-item">User Communication</a>
        </div>
        <div class="nav-divider"></div>
        <div class="nav-section">
          <div class="nav-section-title">Identity & Access</div>
          <a href="../identity/index.html" class="nav-item">Identity Overview</a>
          <a href="../identity/hybrid-setup.html" class="nav-item">Hybrid Identity</a>
          <a href="../identity/conditional-access.html" class="nav-item">Conditional Access</a>
          <a href="../identity/pim.html" class="nav-item">PIM Configuration</a>
        </div>
        <div class="nav-divider"></div>
        <div class="nav-section">
          <div class="nav-section-title">Infrastructure</div>
          <a href="../infrastructure/index.html" class="nav-item">Infrastructure Overview</a>
          <a href="../infrastructure/landing-zone.html" class="nav-item">Landing Zone</a>
          <a href="../infrastructure/network-architecture.html" class="nav-item">Network Architecture</a>
          <a href="../infrastructure/workload-migration.html" class="nav-item">Workload Migration</a>
        </div>
        <div class="nav-divider"></div>
        <div class="nav-section">
          <div class="nav-section-title">Operations</div>
          <a href="../operations/parallel-ops.html" class="nav-item">Parallel Operations</a>
          <a href="../operations/soc-workflows.html" class="nav-item">SOC Workflows</a>
          <a href="../operations/integration.html" class="nav-item">Platform Integration</a>
          <a href="../operations/xdr-integration.html" class="nav-item">XDR Integration</a>
        </div>
        <div class="nav-divider"></div>
        <div class="nav-section">
          <div class="nav-section-title">Resources</div>
          <a href="../resources/timeline.html" class="nav-item">Project Timeline</a>
          <a href="../resources/raci.html" class="nav-item">RACI Matrix</a>
          <a href="../resources/infrastructure-reference.html" class="nav-item">Infrastructure Reference</a>
          <a href="../resources/scripts.html" class="nav-item">Scripts & Queries</a>
          <a href="../resources/data-dictionary.html" class="nav-item">Data Dictionary</a>
          <a href="../resources/templates.html" class="nav-item">Templates</a>
          <a href="../resources/splunk-reference.html" class="nav-item">Splunk Reference</a>
          <a href="../resources/alternative-architectures.html" class="nav-item">Alternative Architectures</a>
        </div>
        <div class="nav-divider"></div>
        <div class="nav-section">
          <div class="nav-section-title">Runbooks</div>
          <a href="../resources/mde-onboarding.html" class="nav-item">MDE Onboarding</a>
          <a href="../resources/mde-offboarding.html" class="nav-item">MDE Offboarding</a>
          <a href="../resources/incident-response.html" class="nav-item">Incident Response</a>
          <a href="../resources/operational-procedures.html" class="nav-item">Operational Procedures</a>
        </div>
        <div class="nav-divider"></div>
        <div class="nav-section">
          <div class="nav-section-title">Troubleshooting</div>
          <a href="../troubleshooting/index.html" class="nav-item">Common Issues</a>
          <a href="../troubleshooting/siem-issues.html" class="nav-item">SIEM Issues</a>
          <a href="../troubleshooting/mde-issues.html" class="nav-item">MDE Issues</a>
          <a href="../troubleshooting/dlp-issues.html" class="nav-item">DLP Issues</a>
          <a href="../troubleshooting/agent-conflicts.html" class="nav-item">Agent Conflicts</a>
        </div>
        <div class="nav-divider"></div>
        <div class="nav-section">
          <div class="nav-section-title">Career</div>
          <a href="../career-narrative.html" class="nav-item">Career Narrative</a>
          <a href="../interview-prep.html" class="nav-item">Interview Prep (Full)</a>
          <a href="../interview-prep-v2.html" class="nav-item">Interview Prep v2</a>
          <a href="../interview-technical-reference.html" class="nav-item">Technical Reference</a>
        </div>
      </nav>
    </aside>
    <button class="mobile-menu-toggle" aria-label="Toggle menu">
      <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M3 12h18M3 6h18M3 18h18"></path></svg>
    </button>
    <div class="sidebar-overlay"></div>
    <main class="main-content">
      <div class="content-wrapper">
        <nav class="breadcrumb">
          <a href="../index.html">Home</a>
          <span class="breadcrumb-separator">/</span>
          <a href="scripts.html">Resources</a>
          <span class="breadcrumb-separator">/</span>
          <span class="breadcrumb-current">Splunk Reference</span>
        </nav>

        <div class="page-header">
          <h1>Splunk Knowledge Reference</h1>
          <p class="intro-text">
            Comprehensive reference for Splunk architecture, SPL queries, and deployment concepts. Organized to build conceptual understanding and demonstrate knowledge during interviews.
          </p>
        </div>

        <div class="callout info">
          <div class="callout-title">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"/></svg>
            Purpose
          </div>
          <div class="callout-content">
            <p>This page serves as a learning reference and interview preparation aid. It maps Splunk concepts to your existing Sentinel/SIEM knowledge to accelerate understanding.</p>
          </div>
        </div>

        <div class="callout warning">
          <div class="callout-title">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M1 21h22L12 2 1 21zm12-3h-2v-2h2v2zm0-4h-2v-4h2v4z"/></svg>
            The Fundamental Architectural Difference
          </div>
          <div class="callout-content">
            <p><strong>Splunk is SIEM-first:</strong> You ingest everything you need and build detections and correlations yourself. Splunk becomes the single source of truth. If correlation exists, you wrote it.</p>
            <p style="margin-top: 0.5rem;"><strong>Microsoft is XDR-first:</strong> Detections and correlation happen upstream in XDR, and Sentinel focuses on enterprise context. Detection ownership is shared with Microsoft.</p>
            <p style="margin-top: 0.5rem;">This is not a feature comparison â€” it's a fundamentally different approach to security operations. When migrating from Splunk to Sentinel, you're not doing lift-and-shift rules â€” you're doing detection re-architecture.</p>
          </div>
        </div>

        <h2>RevFlow's Platform Split: Sentinel (Security) vs Splunk (Operations)</h2>

        <div class="callout success">
          <div class="callout-title">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/></svg>
            Platform Ownership Model
          </div>
          <div class="callout-content">
            <p><strong>Security owns Sentinel + XDR.</strong> Engineering/SRE owns Splunk Cloud.</p>
            <p>This is intentional separation of concerns â€” security logs for security use cases, operational logs for operational use cases.</p>
          </div>
        </div>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>Platform</th><th>Owner</th><th>Data Types</th><th>Use Cases</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Microsoft Sentinel + XDR</strong></td>
                <td>Security Team</td>
                <td>Identity (Entra ID), XDR alerts, network security, SaaS security, cloud security</td>
                <td>Threat detection, incident response, compliance, security correlation</td>
              </tr>
              <tr>
                <td><strong>Splunk Cloud</strong></td>
                <td>Engineering / SRE</td>
                <td>Application performance, API logs, Kubernetes, business transactions</td>
                <td>APM, troubleshooting, capacity planning, feature usage</td>
              </tr>
            </tbody>
          </table>
        </div>

        <h3>What Stays in Splunk (NOT Migrated to Sentinel)</h3>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>Index</th><th>Owner</th><th>Volume</th><th>Why NOT in Sentinel</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><code>app_perf</code></td>
                <td>SRE</td>
                <td>~100 GB/day</td>
                <td>APM data â€” operational, not security</td>
              </tr>
              <tr>
                <td><code>api_logs</code></td>
                <td>Engineering</td>
                <td>~50 GB/day</td>
                <td>API debugging â€” development use case</td>
              </tr>
              <tr>
                <td><code>k8s_logs</code></td>
                <td>SRE</td>
                <td>~80 GB/day</td>
                <td>Container operations â€” platform engineering</td>
              </tr>
              <tr>
                <td><code>business_txn</code></td>
                <td>Product</td>
                <td>~30 GB/day</td>
                <td>Feature analytics â€” product management</td>
              </tr>
            </tbody>
          </table>
        </div>

        <h3>Interview Talking Point</h3>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">Why Not Consolidate Everything in One Platform?</span></div>
          <pre><code>"We intentionally maintain Splunk for operational logs alongside Sentinel 
for security. Here's why:

1. OWNERSHIP CLARITY
   Security team owns security data in Sentinel. Engineering owns operational 
   data in Splunk. No confusion about who maintains what.

2. COST OPTIMIZATION
   Sentinel pricing is per-GB. Ingesting 300+ GB/day of app performance logs 
   would cost ~$25K/month with no security value. Splunk Cloud handles 
   operational scale better for this use case.

3. USE CASE ALIGNMENT
   XDR integration, identity correlation, and security detections work 
   natively in Sentinel. APM dashboards, Kubernetes monitoring, and 
   business analytics work better in Splunk.

4. QUERY SPECIALIZATION
   SOC analysts stay in Sentinel. SRE stays in Splunk. Each team uses 
   the tool optimized for their workflows.

The key insight: 'One platform for everything' sounds efficient but often 
creates a bloated, expensive system where no use case is well-served. 
Purpose-fit platforms with clear ownership work better."</code></pre>
        </div>

        <p>In Splunk Enterprise Security, detection works this way:</p>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>Step</th><th>What Happens</th><th>Who Owns It</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>1. Ingest Everything</strong></td>
                <td>Endpoint, identity, email, network, cloud, custom apps â†’ Splunk is the single source of truth</td>
                <td>You</td>
              </tr>
              <tr>
                <td><strong>2. Build Detections</strong></td>
                <td>Correlation searches, risk-based alerting, threshold logic, MITRE mapping. Even "out-of-the-box" content requires tuning and ownership.</td>
                <td>You</td>
              </tr>
              <tr>
                <td><strong>3. Handle Correlation</strong></td>
                <td>Splunk has no native upstream XDR engine. No automatic cross-domain ML correlation. If correlation exists, you wrote it and maintain it.</td>
                <td>You</td>
              </tr>
            </tbody>
          </table>
        </div>

        <p><strong>Mental model:</strong> Splunk is the brain. Everything feeds it. Detection quality depends entirely on your rules.</p>

        <h2>Splunk Architecture Overview</h2>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">Splunk Data Flow</span></div>
          <pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SPLUNK ARCHITECTURE                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  DATA SOURCES                     COLLECTION                   PROCESSING   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Windows     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Universal   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚             â”‚â”‚
â”‚  â”‚ Servers     â”‚                 â”‚ Forwarder   â”‚             â”‚             â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚             â”‚â”‚
â”‚                                                               â”‚             â”‚â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚  INDEXERS   â”‚â”‚
â”‚  â”‚ Linux       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Universal   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚             â”‚â”‚
â”‚  â”‚ Servers     â”‚                 â”‚ Forwarder   â”‚             â”‚  (Storage   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   + Index)  â”‚â”‚
â”‚                                                               â”‚             â”‚â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚             â”‚â”‚
â”‚  â”‚ Network     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Heavy       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚             â”‚â”‚
â”‚  â”‚ Devices     â”‚  (Syslog)       â”‚ Forwarder   â”‚  (Parse)    â”‚             â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                      â”‚       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚       â”‚
â”‚  â”‚ Cloud/API   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”‚
â”‚  â”‚ Sources     â”‚  (HTTP Event Collector - HEC)                       â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚       â”‚
â”‚                                                                      â”‚       â”‚
â”‚                              SEARCH & VISUALIZATION                  â”‚       â”‚
â”‚                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚       â”‚
â”‚                             â”‚    SEARCH HEADS     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                             â”‚                     â”‚                          â”‚
â”‚                             â”‚  â€¢ SPL Queries      â”‚                          â”‚
â”‚                             â”‚  â€¢ Dashboards       â”‚                          â”‚
â”‚                             â”‚  â€¢ Alerts           â”‚                          â”‚
â”‚                             â”‚  â€¢ Reports          â”‚                          â”‚
â”‚                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                                              â”‚
â”‚                              MANAGEMENT                                      â”‚
â”‚                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                             â”‚  DEPLOYMENT SERVER  â”‚                          â”‚
â”‚                             â”‚  (Config Management)â”‚                          â”‚
â”‚                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
        </div>

        <h3>Core Components</h3>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>Component</th><th>Function</th><th>Sentinel Equivalent</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Universal Forwarder (UF)</strong></td>
                <td>Lightweight agent that collects and forwards data. Minimal processing, low resource usage. Most common deployment.</td>
                <td>Azure Monitor Agent (AMA)</td>
              </tr>
              <tr>
                <td><strong>Heavy Forwarder (HF)</strong></td>
                <td>Full Splunk instance that can parse, filter, and route data before forwarding. Used for syslog aggregation, data transformation.</td>
                <td>Log Analytics Gateway, DCR transformations</td>
              </tr>
              <tr>
                <td><strong>Indexer</strong></td>
                <td>Processes incoming data, creates indexes, stores events, handles search requests for its data.</td>
                <td>Log Analytics workspace (backend)</td>
              </tr>
              <tr>
                <td><strong>Search Head</strong></td>
                <td>User interface for searching, dashboards, alerts. Coordinates distributed searches across indexers.</td>
                <td>Sentinel portal, Log Analytics query UI</td>
              </tr>
              <tr>
                <td><strong>Deployment Server</strong></td>
                <td>Centrally manages forwarder configurations. Pushes apps and settings to forwarders.</td>
                <td>Intune policies, DCR assignments</td>
              </tr>
              <tr>
                <td><strong>Cluster Master / Manager</strong></td>
                <td>Coordinates indexer clustering for replication and high availability.</td>
                <td>Azure's built-in HA (managed)</td>
              </tr>
              <tr>
                <td><strong>License Master</strong></td>
                <td>Manages and enforces Splunk licensing across deployment.</td>
                <td>Azure subscription/billing</td>
              </tr>
            </tbody>
          </table>
        </div>

        <h2>Splunk Deployment Models</h2>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>Model</th><th>Description</th><th>Use Case</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Splunk Cloud</strong></td>
                <td>Fully managed SaaS. Splunk manages indexers, search heads, infrastructure. You manage forwarders and content.</td>
                <td>Most new deployments, cloud-first orgs. Similar to Sentinel.</td>
              </tr>
              <tr>
                <td><strong>Splunk Enterprise (On-Prem)</strong></td>
                <td>Self-managed deployment. Full control over all components. You manage infrastructure, updates, scaling.</td>
                <td>Air-gapped environments, strict data residency, existing investment.</td>
              </tr>
              <tr>
                <td><strong>Hybrid</strong></td>
                <td>Some data in Splunk Cloud, some on-prem. Federated search across both.</td>
                <td>Transition scenarios, specific data sovereignty needs.</td>
              </tr>
            </tbody>
          </table>
        </div>

        <!-- ==================== SPLUNK ES SECTION ==================== -->
        <h2>What Splunk Enterprise Security (ES) Actually Adds</h2>

        <div class="callout critical">
          <div class="callout-title">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"/></svg>
            Critical Distinction
          </div>
          <div class="callout-content">
            <p><strong>Splunk ES is NOT a SIEM engine by itself.</strong> It is a security solution layer that sits on top of Splunk Enterprise.</p>
            <p style="margin-top: 0.5rem;">Think of it as:</p>
            <ul style="margin: 0.5rem 0; padding-left: 1.5rem;">
              <li><strong>Splunk Enterprise</strong> = Platform (data collection, indexing, search)</li>
              <li><strong>Splunk ES</strong> = Security brain + SOC workflows + detection content</li>
            </ul>
            <p style="margin-top: 0.5rem;">This is why ES licensing is expensive and separate â€” you're paying for content maturity and SOC-ready workflows, not just the platform.</p>
          </div>
        </div>

        <h3>1. Prebuilt Security Content (Biggest Value)</h3>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>What ES Adds</th><th>Without ES</th></tr>
            </thead>
            <tbody>
              <tr>
                <td>
                  <strong>Hundreds of prebuilt correlation searches</strong>
                  <ul style="margin: 0.5rem 0; padding-left: 1.2rem;">
                    <li>Mapped to MITRE ATT&CK</li>
                    <li>Endpoint threats</li>
                    <li>Identity abuse</li>
                    <li>Network attacks</li>
                    <li>Cloud misuse</li>
                    <li>Malware, ransomware, lateral movement</li>
                  </ul>
                </td>
                <td>
                  <ul style="margin: 0; padding-left: 1.2rem;">
                    <li>You write everything yourself in SPL</li>
                    <li>No standardized security logic</li>
                    <li>No MITRE mapping out-of-box</li>
                    <li>Months of detection engineering work</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="callout info">
          <div class="callout-title">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"/></svg>
            Why ES Is Expensive
          </div>
          <div class="callout-content">
            <p><strong>Content maturity.</strong> You're paying for years of security research, detection logic, and SOC workflow design â€” not just software licenses.</p>
          </div>
        </div>

        <h3>2. CIM (Common Information Model) Enforcement</h3>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>What ES Adds</th><th>Without ES</th></tr>
            </thead>
            <tbody>
              <tr>
                <td>
                  <strong>Strong dependency on CIM-compliant data models</strong>
                  <ul style="margin: 0.5rem 0; padding-left: 1.2rem;">
                    <li>Normalized views: Authentication, Endpoint, Network Traffic, Malware, Change</li>
                    <li>Cross-source correlation works automatically</li>
                    <li>Vendor-agnostic detections</li>
                  </ul>
                </td>
                <td>
                  <ul style="margin: 0; padding-left: 1.2rem;">
                    <li>CIM is optional</li>
                    <li>Correlation is manual and custom</li>
                    <li>Each vendor requires separate detection logic</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">CIM Data Models</span></div>
          <pre><code>CIM DATA MODELS IN SPLUNK ES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Authentication      â†’ Login success/failure, MFA, session tracking
Endpoint            â†’ Process execution, file changes, registry
Network Traffic     â†’ Flows, connections, bytes transferred
Malware             â†’ AV detections, quarantine, file hashes
Change              â†’ Configuration changes, permission modifications
Web                 â†’ HTTP requests, proxy logs, URL access
Email               â†’ Sender, recipient, attachments, spam
Intrusion Detection â†’ IDS/IPS alerts

WHY THIS MATTERS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Without CIM: "Write detection for Palo Alto, then write same detection    â”‚
â”‚              for Fortinet, then write same detection for Cisco..."        â”‚
â”‚                                                                            â”‚
â”‚ With CIM:    "Write one detection against Network Traffic data model.     â”‚
â”‚              Works for all vendors that map to CIM."                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
        </div>

        <h3>3. Risk-Based Alerting (RBA)</h3>

        <div class="callout warning">
          <div class="callout-title">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M1 21h22L12 2 1 21zm12-3h-2v-2h2v2zm0-4h-2v-4h2v4z"/></svg>
            This Dramatically Reduces Noise
          </div>
          <div class="callout-content">
            <p><strong>Without RBA:</strong> Every alert fires independently. High alert fatigue.</p>
            <p style="margin-top: 0.5rem;"><strong>With RBA:</strong> Events generate risk scores. Risk accumulates per user/host. Alert fires only when risk threshold is crossed.</p>
          </div>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">RBA Flow</span></div>
          <pre><code>RISK-BASED ALERTING FLOW
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

WITHOUT RBA (Traditional Alerting):
  Failed login â†’ ALERT!
  PowerShell executed â†’ ALERT!
  Outbound connection â†’ ALERT!
  Result: 500 alerts/day, SOC overwhelmed

WITH RBA:
  Failed login      â†’ +10 risk points to user "jsmith"
  PowerShell abuse  â†’ +25 risk points to user "jsmith"  
  C2 beaconing      â†’ +40 risk points to user "jsmith"
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Total: 75 points  â†’ EXCEEDS THRESHOLD (50) â†’ ALERT!

EXAMPLE SCENARIO:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ One failed login                     = +5 points   â†’ No alert             â”‚
â”‚ Three failed logins                  = +15 points  â†’ No alert             â”‚
â”‚ Three failed + successful login      = +20 points  â†’ No alert             â”‚
â”‚ Above + PowerShell encoded command   = +45 points  â†’ No alert             â”‚
â”‚ Above + outbound to rare domain      = +70 points  â†’ ALERT (threshold 50) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Result: High-fidelity alerts that represent actual risk accumulation,
        not individual low-confidence events.</code></pre>
        </div>

        <div class="callout success">
          <div class="callout-title">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/></svg>
            Sentinel Equivalent
          </div>
          <div class="callout-content">
            <p>In Microsoft Sentinel, this concept is implemented through <strong>UEBA (User and Entity Behavior Analytics)</strong> and <strong>Fusion</strong> correlation.</p>
            <p style="margin-top: 0.5rem;">UEBA assigns anomaly scores to entities. Fusion correlates low-fidelity signals into high-confidence incidents. Similar outcome, different implementation.</p>
          </div>
        </div>

        <h3>4. SOC Workflow & Incident Management</h3>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>What ES Adds</th><th>Without ES</th></tr>
            </thead>
            <tbody>
              <tr>
                <td>
                  <strong>Notable Events System</strong>
                  <ul style="margin: 0.5rem 0; padding-left: 1.2rem;">
                    <li>Incident Review dashboard</li>
                    <li>Status tracking: New â†’ In Progress â†’ Suppressed â†’ Resolved</li>
                    <li>Analyst assignment</li>
                    <li>Commenting and audit trail</li>
                    <li>SLA tracking</li>
                  </ul>
                </td>
                <td>
                  <ul style="margin: 0; padding-left: 1.2rem;">
                    <li>Splunk is just a search tool</li>
                    <li>Incident tracking happens in ServiceNow, Jira, or Excel</li>
                    <li>No native SOC workflow</li>
                    <li>No analyst performance metrics</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">Notable Event Lifecycle</span></div>
          <pre><code>NOTABLE EVENT WORKFLOW IN SPLUNK ES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Correlation Search fires
        â†“
Notable Event created
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INCIDENT REVIEW DASHBOARD                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Status: New â†’ Assigned â†’ In Progress â†’ Pending â†’ Resolved/Closed           â”‚
â”‚                                                                             â”‚
â”‚ Urgency: Critical | High | Medium | Low | Informational                    â”‚
â”‚                                                                             â”‚
â”‚ Owner: [Analyst Name]                                                       â”‚
â”‚                                                                             â”‚
â”‚ Comments: Analyst notes, investigation steps, findings                      â”‚
â”‚                                                                             â”‚
â”‚ Related Events: Drill-down to raw events, timeline view                     â”‚
â”‚                                                                             â”‚
â”‚ Disposition: True Positive | False Positive | Benign True Positive          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Sentinel Equivalent: Incidents in M365 Defender unified queue (security.microsoft.com)
                     Same workflow concept, different interface.</code></pre>
        </div>

        <h3>5. Threat Intelligence Framework</h3>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>What ES Adds</th><th>Without ES</th></tr>
            </thead>
            <tbody>
              <tr>
                <td>
                  <strong>Native TI Integration</strong>
                  <ul style="margin: 0.5rem 0; padding-left: 1.2rem;">
                    <li>Built-in indicator ingestion (STIX/TAXII, CSV, API)</li>
                    <li>Automatic matching against events</li>
                    <li>Confidence scoring per indicator</li>
                    <li>Expiration handling (IOC TTL)</li>
                    <li>TI correlation dashboards</li>
                  </ul>
                </td>
                <td>
                  <ul style="margin: 0; padding-left: 1.2rem;">
                    <li>TI ingestion is custom scripting</li>
                    <li>Matching logic must be written manually</li>
                    <li>No standard indicator schema</li>
                    <li>No expiration management</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <h3>6. Advanced Security Dashboards</h3>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>What ES Adds</th><th>Without ES</th></tr>
            </thead>
            <tbody>
              <tr>
                <td>
                  <strong>SOC-Ready Dashboards</strong>
                  <ul style="margin: 0.5rem 0; padding-left: 1.2rem;">
                    <li>Security Posture dashboard</li>
                    <li>MITRE ATT&CK coverage views</li>
                    <li>Risk heatmaps (user/host)</li>
                    <li>Analyst productivity metrics</li>
                    <li>Detection coverage gap analysis</li>
                    <li>Executive security summaries</li>
                  </ul>
                </td>
                <td>
                  <ul style="margin: 0; padding-left: 1.2rem;">
                    <li>You build dashboards from scratch</li>
                    <li>No security-specific views out-of-box</li>
                    <li>MITRE mapping is manual effort</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>
        </div>

        <h3>What ES Does NOT Add (Important)</h3>

        <div class="callout warning">
          <div class="callout-title">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M1 21h22L12 2 1 21zm12-3h-2v-2h2v2zm0-4h-2v-4h2v4z"/></svg>
            Common Misconceptions
          </div>
          <div class="callout-content">
            <p><strong>ES does NOT:</strong></p>
            <ul style="margin: 0.5rem 0; padding-left: 1.5rem;">
              <li>âŒ Collect logs (forwarders do that)</li>
              <li>âŒ Index data (indexers do that)</li>
              <li>âŒ Replace EDR (you still need endpoint agents)</li>
              <li>âŒ Replace SOAR (Splunk SOAR is a separate product)</li>
              <li>âŒ Eliminate the need for tuning (content is a starting point, not finished)</li>
            </ul>
            <p style="margin-top: 0.5rem;"><strong>ES assumes:</strong></p>
            <ul style="margin: 0.5rem 0; padding-left: 1.5rem;">
              <li>âœ… You already have good data (properly parsed, CIM-compliant)</li>
              <li>âœ… You already have log pipelines (forwarders configured)</li>
              <li>âœ… You will tune and maintain content</li>
            </ul>
          </div>
        </div>

        <h3>ES vs Sentinel Feature Mapping</h3>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>Splunk ES Feature</th><th>Microsoft Sentinel Equivalent</th></tr>
            </thead>
            <tbody>
              <tr>
                <td>Correlation Searches</td>
                <td>Analytics Rules (Scheduled, NRT, Fusion)</td>
              </tr>
              <tr>
                <td>Notable Events</td>
                <td>Incidents</td>
              </tr>
              <tr>
                <td>Risk-Based Alerting</td>
                <td>UEBA + Fusion correlation</td>
              </tr>
              <tr>
                <td>CIM Data Models</td>
                <td>ASIM (Advanced Security Information Model)</td>
              </tr>
              <tr>
                <td>Threat Intelligence</td>
                <td>Threat Intelligence blade + MDTI integration</td>
              </tr>
              <tr>
                <td>Incident Review</td>
                <td>M365 Defender unified queue (security.microsoft.com)</td>
              </tr>
              <tr>
                <td>MITRE Coverage</td>
                <td>MITRE ATT&CK blade in Sentinel</td>
              </tr>
              <tr>
                <td>Splunk SOAR</td>
                <td>Logic Apps / Sentinel Playbooks</td>
              </tr>
              <tr>
                <td>ES Content Update</td>
                <td>Content Hub solutions</td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="callout success" style="border-left: 4px solid #22c55e;">
          <div class="callout-title">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/></svg>
            ğŸ¯ Interview Answer: "What does Splunk ES add over base Splunk?"
          </div>
          <div class="callout-content">
            <div class="code-block">
              <div class="code-header"><span class="code-lang">Response</span></div>
              <pre><code>"Splunk ES is the security brain on top of Splunk Enterprise. The base 
platform handles log collection and indexing. ES adds:

1. PREBUILT DETECTION CONTENT
   Hundreds of correlation searches mapped to MITRE ATT&CK. Without ES, 
   you write everything from scratch.

2. CIM ENFORCEMENT
   Common Information Model normalizes data across vendors. Enables 
   vendor-agnostic detections â€” write once, works for all.

3. RISK-BASED ALERTING
   Instead of alert-per-event, ES accumulates risk scores per entity. 
   Alerts fire when threshold is crossed. Dramatically reduces noise.

4. SOC WORKFLOW
   Notable Events, Incident Review dashboard, analyst assignment, 
   status tracking. Without ES, Splunk is just a search tool.

5. THREAT INTELLIGENCE
   Native TI ingestion, automatic matching, confidence scoring, 
   expiration handling.

ES is expensive because you're paying for content maturity and SOC-ready 
workflows, not just software. In Sentinel, many of these features are 
built-in (Analytics Rules, UEBA, Incidents, Content Hub) â€” it's a 
different licensing model but similar capability."</code></pre>
            </div>
          </div>
        </div>

        <h2>SPL (Search Processing Language)</h2>

        <div class="callout info">
          <div class="callout-title">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"/></svg>
            SPL vs KQL
          </div>
          <div class="callout-content">
            <p>SPL uses pipe-based syntax like Unix commands. KQL uses a more SQL-like syntax. Both achieve similar results with different approaches.</p>
          </div>
        </div>

        <h3>Basic SPL Syntax</h3>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">SPL Basics</span></div>
          <pre><code># Basic search (implicit AND)
index=main sourcetype=WinEventLog EventCode=4625

# Time range
index=main earliest=-24h latest=now

# Field extraction
index=main | fields host, source, _time, user

# Filtering with where
index=main | where status="failed"

# Counting
index=main | stats count by host

# Multiple conditions
index=main sourcetype=WinEventLog (EventCode=4624 OR EventCode=4625)</code></pre>
        </div>

        <h3>SPL â†” KQL Comparison</h3>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>Operation</th><th>SPL (Splunk)</th><th>KQL (Sentinel)</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Basic search</strong></td>
                <td><code>index=main error</code></td>
                <td><code>search "error"</code></td>
              </tr>
              <tr>
                <td><strong>Filter by field</strong></td>
                <td><code>index=main status=500</code></td>
                <td><code>| where status == 500</code></td>
              </tr>
              <tr>
                <td><strong>Time filter</strong></td>
                <td><code>earliest=-1h latest=now</code></td>
                <td><code>| where TimeGenerated > ago(1h)</code></td>
              </tr>
              <tr>
                <td><strong>Count by field</strong></td>
                <td><code>| stats count by host</code></td>
                <td><code>| summarize count() by Computer</code></td>
              </tr>
              <tr>
                <td><strong>Unique values</strong></td>
                <td><code>| stats dc(user) as unique_users</code></td>
                <td><code>| summarize dcount(user)</code></td>
              </tr>
              <tr>
                <td><strong>Top N</strong></td>
                <td><code>| top 10 user</code></td>
                <td><code>| top 10 by user</code></td>
              </tr>
              <tr>
                <td><strong>Table output</strong></td>
                <td><code>| table _time, host, message</code></td>
                <td><code>| project TimeGenerated, Computer, Message</code></td>
              </tr>
              <tr>
                <td><strong>Rename field</strong></td>
                <td><code>| rename src_ip as SourceIP</code></td>
                <td><code>| extend SourceIP = src_ip</code></td>
              </tr>
              <tr>
                <td><strong>Sort</strong></td>
                <td><code>| sort - _time</code></td>
                <td><code>| order by TimeGenerated desc</code></td>
              </tr>
              <tr>
                <td><strong>Join</strong></td>
                <td><code>| join type=inner host [search index=assets]</code></td>
                <td><code>| join kind=inner (Assets) on Computer</code></td>
              </tr>
            </tbody>
          </table>
        </div>

        <h3>Common SPL Commands</h3>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">SPL Commands Reference</span></div>
          <pre><code># STATS - Aggregate data
| stats count, avg(response_time), max(bytes) by host

# TIMECHART - Time-based aggregation (for dashboards)
| timechart span=1h count by status

# EVAL - Create/modify fields
| eval status_category=if(status>=400, "error", "success")

# REX - Regex field extraction
| rex field=message "user=(?&lt;username&gt;\w+)"

# TRANSACTION - Group related events
| transaction session_id maxspan=30m

# LOOKUP - Enrich with external data
| lookup threat_intel ip as src_ip OUTPUT threat_type, severity

# DEDUP - Remove duplicates
| dedup host, user

# EVENTSTATS - Stats without reducing rows
| eventstats avg(response_time) as avg_rt by host

# STREAMSTATS - Running calculations
| streamstats count as event_number by session_id

# TSTATS - Fast indexed field searches
| tstats count where index=main by host, sourcetype</code></pre>
        </div>

        <h3>Security-Focused SPL Examples</h3>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">SPL - Failed Login Detection</span></div>
          <pre><code># Failed Windows logins in last 24 hours
index=wineventlog sourcetype=WinEventLog:Security EventCode=4625 earliest=-24h
| stats count by src_ip, user, host
| where count > 5
| sort - count

# KQL equivalent:
SecurityEvent
| where TimeGenerated > ago(24h)
| where EventID == 4625
| summarize count() by IpAddress, Account, Computer
| where count_ > 5
| order by count_ desc</code></pre>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">SPL - Process Execution</span></div>
          <pre><code># Suspicious process execution (encoded PowerShell)
index=wineventlog sourcetype=WinEventLog:Security EventCode=4688
| search CommandLine="*-enc*" OR CommandLine="*-encoded*"
| table _time, host, user, CommandLine
| sort - _time

# KQL equivalent:
SecurityEvent
| where EventID == 4688
| where CommandLine contains "-enc" or CommandLine contains "-encoded"
| project TimeGenerated, Computer, Account, CommandLine
| order by TimeGenerated desc</code></pre>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">SPL - Outbound Connection Anomaly</span></div>
          <pre><code># Unusual outbound connections by volume
index=network sourcetype=firewall action=allowed direction=outbound
| stats sum(bytes_out) as total_bytes, count by src_ip, dest_ip
| where total_bytes > 1000000000
| sort - total_bytes
| lookup geo_ip ip as dest_ip OUTPUT country

# KQL equivalent:
CommonSecurityLog
| where DeviceAction == "Allow"
| summarize TotalBytes=sum(SentBytes), Count=count() by SourceIP, DestinationIP
| where TotalBytes > 1000000000
| order by TotalBytes desc</code></pre>
        </div>

        <h2>Splunk Enterprise Security (ES)</h2>

        <div class="callout info">
          <div class="callout-title">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"/></svg>
            What is Splunk ES?
          </div>
          <div class="callout-content">
            <p>Splunk Enterprise Security is a premium SIEM application that runs on top of Splunk. It provides security-specific features like Notable Events, Risk Scoring, and pre-built content. Similar to how Sentinel's SIEM features are built into the platform.</p>
          </div>
        </div>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>Splunk ES Feature</th><th>Description</th><th>Sentinel Equivalent</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Notable Events</strong></td>
                <td>Security alerts from correlation searches. Triaged in Incident Review dashboard.</td>
                <td>Incidents</td>
              </tr>
              <tr>
                <td><strong>Correlation Searches</strong></td>
                <td>Scheduled searches that generate Notable Events when conditions are met.</td>
                <td>Analytics Rules</td>
              </tr>
              <tr>
                <td><strong>Risk-Based Alerting (RBA)</strong></td>
                <td>Assigns risk scores to entities. Alerts when cumulative risk exceeds threshold.</td>
                <td>UEBA, Entity behavior</td>
              </tr>
              <tr>
                <td><strong>Asset & Identity Framework</strong></td>
                <td>Enrich events with asset/identity context from HR, CMDB.</td>
                <td>Watchlists, Entity mapping</td>
              </tr>
              <tr>
                <td><strong>Threat Intelligence Framework</strong></td>
                <td>Ingest and correlate IOCs from threat intel feeds.</td>
                <td>Threat Intelligence connectors</td>
              </tr>
              <tr>
                <td><strong>Security Posture Dashboard</strong></td>
                <td>Executive view of security metrics and trends.</td>
                <td>Workbooks, Overview dashboard</td>
              </tr>
              <tr>
                <td><strong>Adaptive Response</strong></td>
                <td>Automated response actions triggered by alerts.</td>
                <td>Playbooks (Logic Apps)</td>
              </tr>
            </tbody>
          </table>
        </div>

        <h2>Configuration Files</h2>

        <p>Splunk configuration is file-based. Understanding these files helps with troubleshooting and deployment:</p>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>File</th><th>Purpose</th><th>Location</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>inputs.conf</strong></td>
                <td>Define data inputs (files, network ports, scripts)</td>
                <td>$SPLUNK_HOME/etc/system/local/ or apps</td>
              </tr>
              <tr>
                <td><strong>outputs.conf</strong></td>
                <td>Define where forwarders send data (indexers)</td>
                <td>Forwarders</td>
              </tr>
              <tr>
                <td><strong>props.conf</strong></td>
                <td>Define sourcetype properties, field extractions, timestamp parsing</td>
                <td>Search heads, indexers</td>
              </tr>
              <tr>
                <td><strong>transforms.conf</strong></td>
                <td>Define field extractions, lookups, routing rules</td>
                <td>Works with props.conf</td>
              </tr>
              <tr>
                <td><strong>indexes.conf</strong></td>
                <td>Define index settings (retention, storage paths)</td>
                <td>Indexers</td>
              </tr>
              <tr>
                <td><strong>savedsearches.conf</strong></td>
                <td>Define alerts, scheduled searches, reports</td>
                <td>Search heads</td>
              </tr>
              <tr>
                <td><strong>server.conf</strong></td>
                <td>Server settings (clustering, SSL, general config)</td>
                <td>All components</td>
              </tr>
            </tbody>
          </table>
        </div>

        <h2>Data Onboarding Process</h2>

        <div class="flow-diagram">
          <div class="flow-step">
            <div class="flow-step-number">1</div>
            <div class="flow-step-content">
              <strong>Identify Source</strong><br>
              What data? Where is it? Format? Volume expected?
            </div>
          </div>
          <div class="flow-connector">â†“</div>
          <div class="flow-step">
            <div class="flow-step-number">2</div>
            <div class="flow-step-content">
              <strong>Choose Collection Method</strong><br>
              Universal Forwarder (files) | HEC (API) | Syslog (network) | DB Connect (databases)
            </div>
          </div>
          <div class="flow-connector">â†“</div>
          <div class="flow-step">
            <div class="flow-step-number">3</div>
            <div class="flow-step-content">
              <strong>Configure Inputs</strong><br>
              inputs.conf or Add Data wizard. Define sourcetype, index, host.
            </div>
          </div>
          <div class="flow-connector">â†“</div>
          <div class="flow-step">
            <div class="flow-step-number">4</div>
            <div class="flow-step-content">
              <strong>Configure Parsing</strong><br>
              props.conf/transforms.conf. Timestamp extraction, field extraction, line breaking.
            </div>
          </div>
          <div class="flow-connector">â†“</div>
          <div class="flow-step">
            <div class="flow-step-number">5</div>
            <div class="flow-step-content">
              <strong>Validate</strong><br>
              Search for data. Check field extraction. Verify timestamp. Test volume.
            </div>
          </div>
          <div class="flow-connector">â†“</div>
          <div class="flow-step">
            <div class="flow-step-number">6</div>
            <div class="flow-step-content">
              <strong>Build Content</strong><br>
              Dashboards, alerts, reports. Enable ES content if applicable.
            </div>
          </div>
        </div>

        <h2>Splunk Licensing</h2>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>License Type</th><th>Model</th><th>Notes</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Ingest-Based</strong></td>
                <td>GB/day indexed</td>
                <td>Traditional model. Pay for data volume ingested.</td>
              </tr>
              <tr>
                <td><strong>Workload-Based (SVCs)</strong></td>
                <td>Splunk Virtual Compute Units</td>
                <td>Newer model. Based on compute used, not just volume.</td>
              </tr>
              <tr>
                <td><strong>Splunk Cloud</strong></td>
                <td>GB/day or workload</td>
                <td>SaaS pricing, includes infrastructure.</td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="callout warning">
          <div class="callout-title">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M1 21h22L12 2 1 21zm12-3h-2v-2h2v2zm0-4h-2v-4h2v4z"/></svg>
            License Violations
          </div>
          <div class="callout-content">
            <p>If you exceed your daily ingest license, Splunk will warn you. Multiple violations in a rolling window can disable search capabilities until resolved. Monitor license usage proactively.</p>
          </div>
        </div>

        <h2>Best Practices</h2>
        
        <div class="callout info">
          <div class="callout-title">
            <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"/></svg>
            Splunk Deployment Best Practices
          </div>
          <div class="callout-content">
            <ul style="margin: 0; padding-left: 1.5rem;">
              <li><strong>Use Universal Forwarders:</strong> Lightweight, easier to manage than Heavy Forwarders</li>
              <li><strong>Index strategy:</strong> Separate indexes by sourcetype/retention needs</li>
              <li><strong>Use apps:</strong> Package configurations as apps for portability</li>
              <li><strong>Deployment Server:</strong> Centrally manage forwarder configs, don't manually configure each</li>
              <li><strong>Test parsing:</strong> Validate props/transforms in dev before production</li>
              <li><strong>Monitor license:</strong> Set up alerts for license usage approaching limits</li>
              <li><strong>Use tstats:</strong> For high-volume searches, use accelerated data models</li>
            </ul>
          </div>
        </div>

        <!-- ==================== SPLUNK DATA PIPELINE - DEEP DIVE ==================== -->
        <h2>Splunk Data Pipeline â€” Deep Dive</h2>

        <p>Understanding the Splunk data pipeline is <strong>critical for interviews</strong> and actual implementation. This section covers how data flows from source to searchable events â€” the equivalent of understanding DCRs in Sentinel.</p>

        <div class="callout critical">
          <div class="callout-title"><svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"/></svg>The Data Pipeline Mental Model</div>
          <div class="callout-content">
            <p>Splunk processes data in <strong>three phases</strong>: Input â†’ Parsing â†’ Indexing</p>
            <p>Unlike Sentinel where "stream determines table", in Splunk <strong>you control every step</strong> â€” but that means you're responsible for configuring it correctly.</p>
          </div>
        </div>

        <h3>End-to-End Data Flow</h3>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">Splunk Data Pipeline â€” Complete Flow</span></div>
          <pre><code>DATA SOURCE (Application, OS, Network Device)
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 1: INPUT (Forwarder or Direct)                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Read from: file, syslog, API, script, Windows Event Log                  â”‚
â”‚  â€¢ Assign: source, sourcetype, host, index                                  â”‚
â”‚  â€¢ Configure in: inputs.conf                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 2: PARSING (Heavy Forwarder or Indexer)                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Line breaking: Split raw data into individual events                     â”‚
â”‚  â€¢ Timestamp extraction: Identify and parse _time                           â”‚
â”‚  â€¢ Character encoding: Handle UTF-8, ASCII, etc.                            â”‚
â”‚  â€¢ Transformations: Field extraction, routing, filtering                    â”‚
â”‚  â€¢ Configure in: props.conf + transforms.conf                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 3: INDEXING (Indexer)                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Segmentation: Break events into searchable segments                      â”‚
â”‚  â€¢ Index-time field extraction: Extract fields at write time                â”‚
â”‚  â€¢ Compression: Compress and store in buckets                               â”‚
â”‚  â€¢ Write to disk: Store in designated index                                 â”‚
â”‚  â€¢ Configure in: indexes.conf                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 4: SEARCH (Search Head)                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Search-time field extraction: Extract fields when queried                â”‚
â”‚  â€¢ Lookups: Enrich with external data                                       â”‚
â”‚  â€¢ Correlation: Join events, transaction grouping                           â”‚
â”‚  â€¢ Output: Results, dashboards, alerts                                      â”‚
â”‚  â€¢ Configure in: props.conf (search-time), lookups, savedsearches.conf      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COMPARISON TO SENTINEL:
â€¢ Splunk's inputs.conf â‰ˆ DCR dataSources
â€¢ Splunk's props.conf + transforms.conf â‰ˆ DCR transformations (KQL)
â€¢ Splunk's indexes.conf â‰ˆ LAW table configuration
â€¢ Splunk's sourcetype â‰ˆ DCR stream (but more flexible)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
        </div>

        <!-- ==================== SOURCE, SOURCETYPE, HOST, INDEX ==================== -->
        <h3>The Four Metadata Fields (Critical Concepts)</h3>

        <p>Every event in Splunk has four critical metadata fields assigned at input time:</p>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>Field</th><th>Purpose</th><th>Example</th><th>Sentinel Equivalent</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>source</strong></td>
                <td>Where data came from (file path, network port, script)</td>
                <td><code>/var/log/auth.log</code><br><code>UDP:514</code></td>
                <td>Similar to Source field in logs</td>
              </tr>
              <tr>
                <td><strong>sourcetype</strong></td>
                <td>Format/type of data â€” determines how Splunk parses it</td>
                <td><code>syslog</code><br><code>pan:traffic</code><br><code>aws:cloudtrail</code></td>
                <td>Closest to DCR stream (Microsoft-Syslog, Microsoft-CEF)</td>
              </tr>
              <tr>
                <td><strong>host</strong></td>
                <td>Machine that generated the event</td>
                <td><code>web01.revflow.com</code></td>
                <td>Computer field</td>
              </tr>
              <tr>
                <td><strong>index</strong></td>
                <td>Data repository where event is stored</td>
                <td><code>main</code><br><code>security</code><br><code>network</code></td>
                <td>Log Analytics Workspace table</td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="callout warning">
          <div class="callout-title"><svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M1 21h22L12 2 1 21zm12-3h-2v-2h2v2zm0-4h-2v-4h2v4z"/></svg>Sourcetype Is King</div>
          <div class="callout-content">
            <p><strong>Sourcetype is the most important metadata field.</strong> It determines:</p>
            <ul style="margin: 0.5rem 0; padding-left: 1.5rem;">
              <li>How Splunk breaks raw data into events (line breaking)</li>
              <li>How timestamps are extracted</li>
              <li>What fields are automatically extracted</li>
              <li>Which props.conf stanzas apply</li>
            </ul>
            <p>Get sourcetype wrong â†’ parsing fails â†’ your data is garbage.</p>
          </div>
        </div>

        <!-- ==================== INPUTS.CONF ==================== -->
        <h3>inputs.conf â€” Data Collection Configuration</h3>

        <p><code>inputs.conf</code> defines <strong>what data Splunk collects and from where</strong>. This is the equivalent of DCR dataSources.</p>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">inputs.conf â€” File Monitoring</span><button class="code-copy-btn">Copy</button></div>
          <pre><code># Monitor a specific file
[monitor:///var/log/auth.log]
sourcetype = linux_secure
index = security
disabled = false

# Monitor all files in a directory
[monitor:///var/log/myapp/*.log]
sourcetype = myapp
index = application
whitelist = \.log$

# Equivalent to DCR logFiles dataSource:
# {
#   "logFiles": [{
#     "name": "myapp-logs",
#     "filePatterns": ["/var/log/myapp/*.log"],
#     "streams": ["Custom-MyApp_CL"]
#   }]
# }</code></pre>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">inputs.conf â€” Syslog (UDP/TCP)</span><button class="code-copy-btn">Copy</button></div>
          <pre><code># Receive syslog on UDP 514
[udp://514]
sourcetype = syslog
index = network
connection_host = ip

# Receive syslog on TCP 514 (more reliable)
[tcp://514]
sourcetype = syslog
index = network
connection_host = dns

# Palo Alto on dedicated port
[udp://5514]
sourcetype = pan:traffic
index = network

# Equivalent to DCR syslog dataSource:
# {
#   "syslog": [{
#     "name": "firewall-logs",
#     "facilityNames": ["local4"],
#     "streams": ["Microsoft-CEF"]
#   }]
# }</code></pre>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">inputs.conf â€” Windows Event Log</span><button class="code-copy-btn">Copy</button></div>
          <pre><code># Collect Windows Security Event Log
[WinEventLog://Security]
index = wineventlog
sourcetype = WinEventLog:Security
disabled = false
# Whitelist specific Event IDs (like DCR xPathQueries)
whitelist = 4624,4625,4648,4672,4720,4726,4728,4732

# Collect Windows System Event Log
[WinEventLog://System]
index = wineventlog
sourcetype = WinEventLog:System
disabled = false

# Equivalent to DCR windowsEventLogs:
# {
#   "windowsEventLogs": [{
#     "name": "security-events",
#     "xPathQueries": ["Security!*[System[(EventID=4624 or EventID=4625)]]"],
#     "streams": ["Microsoft-SecurityEvent"]
#   }]
# }</code></pre>
        </div>

        <!-- ==================== PROPS.CONF ==================== -->
        <h3>props.conf â€” Parsing Configuration (The Brain)</h3>

        <p><code>props.conf</code> is the <strong>most important configuration file</strong>. It controls how Splunk parses raw data into events. This is where you define line breaking, timestamp extraction, and field extractions.</p>

        <div class="callout critical">
          <div class="callout-title"><svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"/></svg>props.conf Stanza Structure</div>
          <div class="callout-content">
            <p>Stanzas in props.conf can be based on:</p>
            <ul style="margin: 0.5rem 0; padding-left: 1.5rem;">
              <li><code>[sourcetype]</code> â€” Most common, applies to all data of that sourcetype</li>
              <li><code>[host::hostname]</code> â€” Applies to data from specific host</li>
              <li><code>[source::...path...]</code> â€” Applies to data from specific source path</li>
            </ul>
          </div>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">props.conf â€” Line Breaking</span><button class="code-copy-btn">Copy</button></div>
          <pre><code># Line breaking controls how raw data is split into events
# CRITICAL: Get this wrong and your events are malformed

[myapp_json]
# JSON logs: each line is one event
LINE_BREAKER = ([\r\n]+)
SHOULD_LINEMERGE = false
TRUNCATE = 50000

[myapp_multiline]
# Multiline logs: events start with timestamp pattern
LINE_BREAKER = ([\r\n]+)(?=\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2})
SHOULD_LINEMERGE = false

[myapp_stacktrace]
# Merge continuation lines (stack traces)
SHOULD_LINEMERGE = true
BREAK_ONLY_BEFORE = ^\d{4}-\d{2}-\d{2}
MAX_EVENTS = 256

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# KEY LINE BREAKING SETTINGS:
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LINE_BREAKER       - Regex that matches the break between events
# SHOULD_LINEMERGE   - true = merge lines into events, false = each line is event
# BREAK_ONLY_BEFORE  - Only break when this pattern matches start of line
# TRUNCATE           - Max characters per event (default 10000)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">props.conf â€” Timestamp Extraction</span><button class="code-copy-btn">Copy</button></div>
          <pre><code># Timestamp extraction tells Splunk how to find and parse _time

[myapp]
# Automatic timestamp recognition (usually works)
DATETIME_CONFIG = 
TIME_FORMAT = 
TIME_PREFIX = 

[custom_timestamp]
# Custom timestamp format
TIME_PREFIX = ^
TIME_FORMAT = %Y-%m-%d %H:%M:%S.%3N
MAX_TIMESTAMP_LOOKAHEAD = 30

[iso8601_logs]
# ISO 8601 format: 2024-01-15T10:30:45.123Z
TIME_FORMAT = %Y-%m-%dT%H:%M:%S.%3NZ

[epoch_logs]
# Unix epoch timestamp
TIME_FORMAT = %s
TIME_PREFIX = "timestamp":

[syslog_timestamp]
# Standard syslog format: Jan 15 10:30:45
TIME_FORMAT = %b %d %H:%M:%S
TZ = UTC

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# KEY TIMESTAMP SETTINGS:
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIME_PREFIX        - Characters before timestamp (regex)
# TIME_FORMAT        - strptime format string
# MAX_TIMESTAMP_LOOKAHEAD - How far to look for timestamp (chars)
# TZ                 - Timezone for events without TZ info
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">props.conf â€” Field Extraction</span><button class="code-copy-btn">Copy</button></div>
          <pre><code># Field extraction (search-time) - extracts fields when you search

[pan:traffic]
# Regex-based field extraction
EXTRACT-src_ip = src=(?&lt;src_ip&gt;\d+\.\d+\.\d+\.\d+)
EXTRACT-dst_ip = dst=(?&lt;dst_ip&gt;\d+\.\d+\.\d+\.\d+)
EXTRACT-action = action=(?&lt;action&gt;\w+)
EXTRACT-bytes = bytes=(?&lt;bytes&gt;\d+)

[linux_secure]
# Extract user from auth.log
EXTRACT-user = user[=:\s]+(?&lt;user&gt;[^\s]+)
EXTRACT-src_ip = from\s+(?&lt;src_ip&gt;\d+\.\d+\.\d+\.\d+)

[json_logs]
# Automatic JSON field extraction
KV_MODE = json

[custom_kv]
# Key-value extraction
KV_MODE = auto
# Custom field delimiter
FIELD_DELIMITER = ,
# Custom key-value delimiter  
FIELD_QUOTE = "

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXTRACTION METHODS:
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXTRACT-<name>     - Regex extraction, names the field
# KV_MODE = json     - Automatic JSON parsing
# KV_MODE = auto     - Automatic key=value parsing
# REPORT-<name>      - References transforms.conf for complex extraction
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
        </div>

        <!-- ==================== TRANSFORMS.CONF ==================== -->
        <h3>transforms.conf â€” Advanced Transformations</h3>

        <p><code>transforms.conf</code> works with props.conf for complex transformations: routing, filtering, field extraction with lookups, and data masking.</p>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">transforms.conf + props.conf â€” Event Routing</span><button class="code-copy-btn">Copy</button></div>
          <pre><code># â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SCENARIO: Route Palo Alto logs to different indexes based on type
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ----- transforms.conf -----
[pan_traffic_route]
REGEX = TRAFFIC
DEST_KEY = _MetaData:Index
FORMAT = network_traffic

[pan_threat_route]
REGEX = THREAT
DEST_KEY = _MetaData:Index
FORMAT = network_threat

[pan_system_route]
REGEX = SYSTEM
DEST_KEY = _MetaData:Index
FORMAT = network_system

# ----- props.conf -----
[pan:log]
TRANSFORMS-route = pan_traffic_route, pan_threat_route, pan_system_route

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RESULT:
# â€¢ TRAFFIC logs â†’ network_traffic index
# â€¢ THREAT logs â†’ network_threat index  
# â€¢ SYSTEM logs â†’ network_system index
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">transforms.conf â€” Event Filtering (Drop)</span><button class="code-copy-btn">Copy</button></div>
          <pre><code># â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SCENARIO: Drop noisy health check logs to save license
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ----- transforms.conf -----
[drop_healthchecks]
REGEX = healthcheck|heartbeat|keepalive
DEST_KEY = queue
FORMAT = nullQueue

[drop_debug_logs]
REGEX = DEBUG|TRACE
DEST_KEY = queue
FORMAT = nullQueue

# ----- props.conf -----
[myapp]
TRANSFORMS-filter = drop_healthchecks, drop_debug_logs

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RESULT: Events matching regex are sent to nullQueue (dropped)
# This is how you filter high-volume noise BEFORE indexing
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">transforms.conf â€” Data Masking (PII)</span><button class="code-copy-btn">Copy</button></div>
          <pre><code># â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SCENARIO: Mask credit card numbers and SSNs before indexing
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ----- transforms.conf -----
[mask_credit_card]
REGEX = (\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?)\d{4}
FORMAT = $1XXXX
DEST_KEY = _raw

[mask_ssn]
REGEX = (\d{3})[-\s]?(\d{2})[-\s]?\d{4}
FORMAT = $1-$2-XXXX
DEST_KEY = _raw

# ----- props.conf -----
[payment_logs]
TRANSFORMS-mask = mask_credit_card, mask_ssn

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RESULT:
# â€¢ 4111-2222-3333-4444 â†’ 4111-2222-3333-XXXX
# â€¢ 123-45-6789 â†’ 123-45-XXXX
# Masking happens BEFORE indexing â€” original data never stored
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
        </div>

        <!-- ==================== INDEX-TIME VS SEARCH-TIME ==================== -->
        <h3>Index-Time vs Search-Time Extraction (Critical Concept)</h3>

        <div class="callout critical">
          <div class="callout-title"><svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"/></svg>This Is a Common Interview Question</div>
          <div class="callout-content">
            <p><strong>Q: "What's the difference between index-time and search-time field extraction?"</strong></p>
            <p>This is fundamental to Splunk architecture and licensing optimization.</p>
          </div>
        </div>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>Aspect</th><th>Index-Time Extraction</th><th>Search-Time Extraction</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>When it happens</strong></td>
                <td>During indexing (data ingestion)</td>
                <td>During search (query execution)</td>
              </tr>
              <tr>
                <td><strong>Storage impact</strong></td>
                <td>Increases index size (fields stored)</td>
                <td>No storage impact</td>
              </tr>
              <tr>
                <td><strong>Search speed</strong></td>
                <td>Faster â€” fields are pre-extracted</td>
                <td>Slower â€” extraction on every search</td>
              </tr>
              <tr>
                <td><strong>Flexibility</strong></td>
                <td>Fixed â€” can't change after indexing</td>
                <td>Flexible â€” can modify extractions anytime</td>
              </tr>
              <tr>
                <td><strong>Use case</strong></td>
                <td>High-volume fields you search constantly</td>
                <td>Most fields â€” default approach</td>
              </tr>
              <tr>
                <td><strong>Configuration</strong></td>
                <td><code>INDEXED_EXTRACTIONS</code> in props.conf</td>
                <td><code>EXTRACT-</code> in props.conf</td>
              </tr>
              <tr>
                <td><strong>Best practice</strong></td>
                <td>Use sparingly â€” only for critical fields</td>
                <td>Default â€” use for most extractions</td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">Index-Time vs Search-Time Example</span><button class="code-copy-btn">Copy</button></div>
          <pre><code># â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SEARCH-TIME EXTRACTION (DEFAULT - USE THIS)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# props.conf
[pan:traffic]
# Extractions happen when you search â€” flexible, no storage overhead
EXTRACT-src_ip = src=(?&lt;src_ip&gt;\d+\.\d+\.\d+\.\d+)
EXTRACT-dst_ip = dst=(?&lt;dst_ip&gt;\d+\.\d+\.\d+\.\d+)
EXTRACT-action = action=(?&lt;action&gt;\w+)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INDEX-TIME EXTRACTION (USE SPARINGLY)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# props.conf â€” only for fields you ALWAYS search on
[pan:traffic]
# This field is stored in the index â€” faster search but uses storage
INDEXED_EXTRACTIONS = json

# For CSV data with header
[csv_data]
INDEXED_EXTRACTIONS = csv
FIELD_NAMES = timestamp, src_ip, dst_ip, action, bytes

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INTERVIEW ANSWER:
# "Search-time extraction is the default and preferred approach because 
# it's flexible â€” you can modify extractions without re-indexing data. 
# Index-time extraction is faster for searching but increases storage 
# and can't be changed after data is indexed. I only use index-time 
# for high-volume, critical fields that are always searched."
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
        </div>

        <!-- ==================== CIM (COMMON INFORMATION MODEL) ==================== -->
        <h3>CIM â€” Common Information Model (Normalization)</h3>

        <p>CIM is Splunk's <strong>normalization framework</strong>. It defines standard field names and data models that allow searches to work across different data sources. This is critical for Splunk Enterprise Security.</p>

        <div class="callout info">
          <div class="callout-title"><svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"/></svg>CIM vs Sentinel Normalization</div>
          <div class="callout-content">
            <p><strong>Sentinel:</strong> Uses ASIM (Advanced Security Information Model) â€” normalized tables like ASimDnsActivityLogs, ASimNetworkSessionLogs</p>
            <p><strong>Splunk:</strong> Uses CIM (Common Information Model) â€” data models like Network_Traffic, Authentication, Web</p>
            <p>Same concept: Normalize diverse sources to common schema for cross-source detection.</p>
          </div>
        </div>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>CIM Data Model</th><th>Use Case</th><th>Key Fields</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Network_Traffic</strong></td>
                <td>Firewall, router, network flow</td>
                <td>src, dest, src_port, dest_port, action, bytes_in, bytes_out</td>
              </tr>
              <tr>
                <td><strong>Authentication</strong></td>
                <td>Login events across all systems</td>
                <td>user, src, dest, action (success/failure), app</td>
              </tr>
              <tr>
                <td><strong>Web</strong></td>
                <td>Web proxy, web server logs</td>
                <td>url, http_method, status, bytes, user_agent, src</td>
              </tr>
              <tr>
                <td><strong>Endpoint</strong></td>
                <td>EDR, endpoint activity</td>
                <td>dest, user, process_name, process_path, action</td>
              </tr>
              <tr>
                <td><strong>Malware</strong></td>
                <td>AV, EDR malware detections</td>
                <td>signature, file_name, file_hash, action, dest</td>
              </tr>
              <tr>
                <td><strong>Change</strong></td>
                <td>Configuration changes</td>
                <td>object, object_category, action, user, result</td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">CIM Field Aliasing â€” props.conf</span><button class="code-copy-btn">Copy</button></div>
          <pre><code># â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SCENARIO: Normalize Palo Alto logs to CIM Network_Traffic model
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ----- props.conf -----
[pan:traffic]
# Palo Alto uses: src, dst, sport, dport
# CIM requires: src, dest, src_port, dest_port

# Field aliases map vendor fields to CIM fields
FIELDALIAS-dest = dst AS dest
FIELDALIAS-src_port = sport AS src_port
FIELDALIAS-dest_port = dport AS dest_port
FIELDALIAS-bytes_in = bytes_received AS bytes_in
FIELDALIAS-bytes_out = bytes_sent AS bytes_out

# Calculated field for CIM compliance
EVAL-action = case(
    action=="allow", "allowed",
    action=="deny", "blocked",
    action=="drop", "blocked",
    1==1, action
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RESULT: 
# â€¢ Palo Alto logs now match CIM Network_Traffic model
# â€¢ ES correlation searches work across all network sources
# â€¢ Single search: index=network | datamodel Network_Traffic search
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">CIM Authentication Model â€” Example</span><button class="code-copy-btn">Copy</button></div>
          <pre><code># â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Normalize Windows, Linux, and Okta auth to CIM Authentication
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ----- Windows Security Events -----
[WinEventLog:Security]
FIELDALIAS-user = Account_Name AS user
FIELDALIAS-src = Workstation_Name AS src
FIELDALIAS-dest = ComputerName AS dest
EVAL-action = case(
    EventCode==4624, "success",
    EventCode==4625, "failure",
    EventCode==4634, "success",
    1==1, "unknown"
)
EVAL-app = "Windows"

# ----- Linux auth.log -----
[linux_secure]
EXTRACT-user = user\s+(?&lt;user&gt;\S+)
EXTRACT-src = from\s+(?&lt;src&gt;\d+\.\d+\.\d+\.\d+)
EVAL-dest = host
EVAL-action = if(match(_raw, "Accepted|session opened"), "success", "failure")
EVAL-app = "Linux"

# ----- Okta -----
[okta:log]
FIELDALIAS-user = actor.alternateId AS user
FIELDALIAS-src = client.ipAddress AS src
EVAL-dest = "Okta"
EVAL-action = case(
    outcome.result=="SUCCESS", "success",
    outcome.result=="FAILURE", "failure",
    1==1, "unknown"
)
EVAL-app = "Okta"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NOW YOU CAN SEARCH:
# | datamodel Authentication search | stats count by user, src, action
# 
# This single search covers Windows, Linux, AND Okta auth events!
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
        </div>

        <!-- ==================== HTTP EVENT COLLECTOR (HEC) ==================== -->
        <h3>HTTP Event Collector (HEC)</h3>

        <p>HEC is Splunk's API for sending data directly over HTTP/HTTPS. Used for cloud sources, custom applications, and serverless functions.</p>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">HEC â€” Sending Events via API</span><button class="code-copy-btn">Copy</button></div>
          <pre><code># â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HEC ENDPOINT FORMAT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# URL: https://splunk-server:8088/services/collector/event
# Headers: 
#   Authorization: Splunk &lt;HEC_TOKEN&gt;
#   Content-Type: application/json

# ----- Single Event -----
curl -k https://splunk.revflow.com:8088/services/collector/event \
  -H "Authorization: Splunk abc123-hec-token" \
  -d '{"event": "User login failed", "source": "myapp", "sourcetype": "myapp:auth"}'

# ----- Event with Fields -----
curl -k https://splunk.revflow.com:8088/services/collector/event \
  -H "Authorization: Splunk abc123-hec-token" \
  -d '{
    "event": {
      "message": "User login failed",
      "user": "jsmith",
      "src_ip": "10.1.1.100",
      "action": "failure"
    },
    "source": "myapp",
    "sourcetype": "myapp:auth",
    "index": "application",
    "time": 1705312245
  }'

# ----- Batch Events (Multiple) -----
curl -k https://splunk.revflow.com:8088/services/collector/event \
  -H "Authorization: Splunk abc123-hec-token" \
  -d '{"event": "Event 1", "sourcetype": "myapp"}
      {"event": "Event 2", "sourcetype": "myapp"}
      {"event": "Event 3", "sourcetype": "myapp"}'

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HEC USE CASES:
# â€¢ AWS Lambda/CloudWatch â†’ Splunk
# â€¢ Azure Functions â†’ Splunk
# â€¢ Custom application logging
# â€¢ CI/CD pipeline events
# â€¢ Webhook receivers
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
        </div>

        <!-- ==================== FORWARDER COMPARISON ==================== -->
        <h3>Universal Forwarder vs Heavy Forwarder (Decision Guide)</h3>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>Aspect</th><th>Universal Forwarder (UF)</th><th>Heavy Forwarder (HF)</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Resource usage</strong></td>
                <td>~512 MB RAM, minimal CPU</td>
                <td>4-8 GB RAM, significant CPU</td>
              </tr>
              <tr>
                <td><strong>Parsing</strong></td>
                <td>No parsing â€” raw data forwarded</td>
                <td>Full parsing â€” props.conf, transforms.conf</td>
              </tr>
              <tr>
                <td><strong>Filtering</strong></td>
                <td>Basic â€” whitelist/blacklist in inputs.conf</td>
                <td>Advanced â€” regex, nullQueue routing</td>
              </tr>
              <tr>
                <td><strong>Routing</strong></td>
                <td>Static â€” all data to configured indexers</td>
                <td>Dynamic â€” route by content, sourcetype, index</td>
              </tr>
              <tr>
                <td><strong>Use case</strong></td>
                <td>Most endpoints â€” servers, workstations</td>
                <td>Syslog aggregation, data transformation</td>
              </tr>
              <tr>
                <td><strong>Install count</strong></td>
                <td>Thousands (one per endpoint)</td>
                <td>Few (centralized collectors)</td>
              </tr>
              <tr>
                <td><strong>Management</strong></td>
                <td>Deployment Server pushes configs</td>
                <td>Manual or version control</td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">When to Use Heavy Forwarder</span></div>
          <pre><code>USE HEAVY FORWARDER WHEN:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. SYSLOG AGGREGATION
   â€¢ Network devices send syslog to HF
   â€¢ HF parses, routes to correct index
   â€¢ Example: All Palo Alto, Cisco, F5 logs â†’ one HF

2. DATA TRANSFORMATION
   â€¢ Need to mask PII before indexing
   â€¢ Need to filter high-volume noise
   â€¢ Need to route based on content

3. PROTOCOL CONVERSION  
   â€¢ Receive syslog UDP â†’ forward to Splunk Cloud (HTTPS)
   â€¢ On-prem sources â†’ cloud Splunk

4. COMPLEX PARSING
   â€¢ Multiline logs that need special handling
   â€¢ Custom sourcetypes with complex extraction

USE UNIVERSAL FORWARDER FOR EVERYTHING ELSE:
â€¢ Windows servers
â€¢ Linux servers  
â€¢ Workstations
â€¢ Any endpoint where you just need to collect files/events

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
        </div>

        <!-- ==================== INDEXES.CONF ==================== -->
        <h3>indexes.conf â€” Index Configuration</h3>

        <p>Indexes are Splunk's data repositories â€” similar to Log Analytics Workspace tables in Sentinel.</p>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">indexes.conf â€” Index Definition</span><button class="code-copy-btn">Copy</button></div>
          <pre><code># â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INDEX CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[security]
homePath = $SPLUNK_DB/security/db
coldPath = $SPLUNK_DB/security/colddb
thawedPath = $SPLUNK_DB/security/thaweddb
# Retention: 90 days hot/warm, then delete
frozenTimePeriodInSecs = 7776000
# Max size: 500 GB
maxTotalDataSizeMB = 512000

[network]
homePath = $SPLUNK_DB/network/db
coldPath = $SPLUNK_DB/network/colddb
thawedPath = $SPLUNK_DB/network/thaweddb
# Retention: 30 days (high volume, less retention)
frozenTimePeriodInSecs = 2592000
maxTotalDataSizeMB = 1024000

[application]
homePath = $SPLUNK_DB/application/db
coldPath = $SPLUNK_DB/application/colddb
thawedPath = $SPLUNK_DB/application/thaweddb
frozenTimePeriodInSecs = 7776000
maxTotalDataSizeMB = 256000

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INDEX STRATEGY BEST PRACTICES:
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â€¢ Separate by retention requirement (security=90 days, network=30 days)
# â€¢ Separate by access control (security team vs IT ops)
# â€¢ Separate by search pattern (frequently searched together = same index)
# â€¢ Don't over-segment (too many indexes = management overhead)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
        </div>

        <!-- ==================== COMPLETE COMPARISON ==================== -->
        <h3>Complete Configuration Mapping: Splunk vs Sentinel</h3>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>Concept</th><th>Splunk</th><th>Sentinel (AMA/DCR)</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>What to collect</strong></td>
                <td>inputs.conf</td>
                <td>DCR dataSources</td>
              </tr>
              <tr>
                <td><strong>How to parse</strong></td>
                <td>props.conf + transforms.conf</td>
                <td>DCR transformKql (limited)</td>
              </tr>
              <tr>
                <td><strong>Where to store</strong></td>
                <td>indexes.conf (index)</td>
                <td>DCR destinations (LAW table via stream)</td>
              </tr>
              <tr>
                <td><strong>Data format identifier</strong></td>
                <td>sourcetype</td>
                <td>stream (Microsoft-Syslog, etc.)</td>
              </tr>
              <tr>
                <td><strong>Normalization</strong></td>
                <td>CIM (field aliases, eval)</td>
                <td>ASIM (normalized tables)</td>
              </tr>
              <tr>
                <td><strong>Filtering before storage</strong></td>
                <td>transforms.conf (nullQueue)</td>
                <td>DCR transformKql with filtering</td>
              </tr>
              <tr>
                <td><strong>API ingestion</strong></td>
                <td>HEC (HTTP Event Collector)</td>
                <td>Data Collection Endpoint (DCE) API</td>
              </tr>
              <tr>
                <td><strong>Agent</strong></td>
                <td>Universal Forwarder</td>
                <td>Azure Monitor Agent</td>
              </tr>
              <tr>
                <td><strong>Intermediate processing</strong></td>
                <td>Heavy Forwarder</td>
                <td>Log Analytics Gateway (limited)</td>
              </tr>
              <tr>
                <td><strong>Central config management</strong></td>
                <td>Deployment Server</td>
                <td>DCR associations (Azure Policy)</td>
              </tr>
            </tbody>
          </table>
        </div>

        <!-- ==================== INTERVIEW ANSWERS ==================== -->
        <h3>Interview-Ready Answers</h3>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">Q: "Walk me through the Splunk data pipeline"</span></div>
          <pre><code>"Data flows through four phases:

1. INPUT PHASE
   The forwarder reads data from files, syslog, WMI, or APIs based on 
   inputs.conf. It assigns source, sourcetype, host, and index metadata.

2. PARSING PHASE  
   Either the Heavy Forwarder or Indexer applies props.conf and 
   transforms.conf. This handles line breaking â€” splitting raw data into 
   events â€” timestamp extraction, character encoding, and transformations 
   like routing or filtering.

3. INDEXING PHASE
   The indexer segments events for searching, applies any index-time 
   field extractions, compresses the data, and writes it to the 
   designated index.

4. SEARCH PHASE
   When users search, search-time field extractions from props.conf 
   are applied. Lookups enrich the data. Results are returned.

The key insight is that sourcetype drives parsing â€” it determines 
which props.conf stanzas apply. Get sourcetype wrong, and your 
data is unparseable."</code></pre>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">Q: "Index-time vs search-time extraction â€” when do you use each?"</span></div>
          <pre><code>"Search-time extraction is the default and should be used for most fields. 
It's flexible â€” I can modify extractions without re-indexing historical data â€” 
and it doesn't increase storage.

Index-time extraction is faster for searching but has tradeoffs: it 
increases index size, can't be changed after indexing, and requires 
re-ingesting data to modify. I only use it for high-volume fields that 
are always searched â€” like src_ip in firewall logs.

In practice, I use search-time for 95% of extractions. The performance 
difference is minimal for most use cases, and flexibility is more 
valuable than marginal speed improvement."</code></pre>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">Q: "What is CIM and why does it matter for Enterprise Security?"</span></div>
          <pre><code>"CIM â€” Common Information Model â€” is Splunk's normalization framework. 
It defines standard field names and data models like Network_Traffic, 
Authentication, and Endpoint.

It matters because Enterprise Security correlation searches are written 
against CIM data models, not raw sourcetypes. If I have firewall logs 
from Palo Alto, Cisco, and Fortinet, they all use different field names. 
CIM field aliases normalize them to common fields like src, dest, 
src_port, dest_port.

Without CIM normalization, I'd have to write separate detections for 
each vendor's log format. With CIM, one detection covers all sources.

Implementation is in props.conf using FIELDALIAS and EVAL commands to 
map vendor fields to CIM fields. It's similar to ASIM in Sentinel â€” 
both solve the same normalization problem."</code></pre>
        </div>

        <div class="code-block">
          <div class="code-header"><span class="code-lang">Q: "When would you use a Heavy Forwarder vs Universal Forwarder?"</span></div>
          <pre><code>"Universal Forwarder is the default for endpoints â€” it's lightweight, 
uses minimal resources, and just forwards raw data to indexers. I'd 
deploy UF on every Windows server, Linux server, and workstation.

Heavy Forwarder is for specialized collection scenarios:

1. Syslog aggregation â€” network devices send syslog to HF, which parses 
   and routes to correct indexes
2. Data transformation â€” masking PII, filtering noise before it 
   consumes license
3. Protocol conversion â€” receiving syslog and forwarding to Splunk Cloud 
   over HTTPS
4. Complex parsing â€” multiline logs that need special handling

The rule is: use UF everywhere possible, HF only when you need 
intermediate processing. HF uses 4-8 GB RAM vs 512 MB for UF, so 
deploying HF everywhere would be wasteful."</code></pre>
        </div>

        <h2>Certifications & Learning Path</h2>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>Certification</th><th>Focus</th><th>Relevance</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Splunk Core Certified User</strong></td>
                <td>Basic SPL, navigation, dashboards</td>
                <td>Foundation â€” validates your SOC analyst experience level</td>
              </tr>
              <tr>
                <td><strong>Splunk Core Certified Power User</strong></td>
                <td>Advanced SPL, reports, data models</td>
                <td>Good target â€” shows depth beyond basic usage</td>
              </tr>
              <tr>
                <td><strong>Splunk Enterprise Certified Admin</strong></td>
                <td>Installation, configuration, management</td>
                <td>Platform engineering focus â€” deployment experience</td>
              </tr>
              <tr>
                <td><strong>Splunk Enterprise Security Certified Admin</strong></td>
                <td>Splunk ES deployment and management</td>
                <td>SIEM-specific â€” most relevant for security consulting</td>
              </tr>
            </tbody>
          </table>
        </div>

        <h2>Resources</h2>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr><th>Resource</th><th>URL</th><th>Notes</th></tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Splunk Docs</strong></td>
                <td>docs.splunk.com</td>
                <td>Official documentation â€” comprehensive</td>
              </tr>
              <tr>
                <td><strong>Splunk Education</strong></td>
                <td>education.splunk.com</td>
                <td>Free training courses, certification paths</td>
              </tr>
              <tr>
                <td><strong>Splunk Lantern</strong></td>
                <td>lantern.splunk.com</td>
                <td>Use case guidance, best practices</td>
              </tr>
              <tr>
                <td><strong>Splunkbase</strong></td>
                <td>splunkbase.splunk.com</td>
                <td>Apps and add-ons marketplace</td>
              </tr>
              <tr>
                <td><strong>Splunk Community</strong></td>
                <td>community.splunk.com</td>
                <td>Forums, Q&A, user discussions</td>
              </tr>
            </tbody>
          </table>
        </div>

        <nav class="page-nav">
          <a href="scripts.html" class="page-nav-link prev"><span class="page-nav-label">Previous</span><span class="page-nav-title">â† Scripts & Queries</span></a>
          <a href="templates.html" class="page-nav-link next"><span class="page-nav-label">Next</span><span class="page-nav-title">Templates â†’</span></a>
        </nav>
      </div>
    </main>
  </div>
  <script src="../js/main.js"></script>
</body>
</html>
